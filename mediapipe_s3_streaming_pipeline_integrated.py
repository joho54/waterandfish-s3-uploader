import os
import sys
import json
import argparse
import logging
import pickle
import gzip
import io
import boto3
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from collections import defaultdict
from config import *
from scipy.interpolate import interp1d
import mediapipe as mp
from mediapipe.python.solutions import pose as mp_pose
from mediapipe.python.solutions import hands as mp_hands
from mediapipe.python.solutions import holistic as mp_holistic



class MediaPipeManager:
    """MediaPipe ê°ì²´ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""

    _instance = None
    _holistic = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(MediaPipeManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if self._holistic is None:
            self._holistic = mp_holistic.Holistic(
                static_image_mode=MEDIAPIPE_STATIC_IMAGE_MODE,
                model_complexity=MEDIAPIPE_MODEL_COMPLEXITY,
                smooth_landmarks=MEDIAPIPE_SMOOTH_LANDMARKS,
                enable_segmentation=MEDIAPIPE_ENABLE_SEGMENTATION,
                smooth_segmentation=MEDIAPIPE_SMOOTH_SEGMENTATION,
                min_detection_confidence=MEDIAPIPE_MIN_DETECTION_CONFIDENCE,
                min_tracking_confidence=MEDIAPIPE_MIN_TRACKING_CONFIDENCE,
            )

    def __enter__(self):
        return self._holistic

    def __exit__(self, exc_type, exc_val, exc_tb):
        # ì „ì—­ ê°ì²´ëŠ” ìœ ì§€í•˜ê³  ì •ë¦¬ë§Œ
        pass

    @classmethod
    def cleanup(cls):
        """ì „ì—­ MediaPipe ê°ì²´ ì •ë¦¬"""
        if cls._holistic:
            cls._holistic.close()
            cls._holistic = None

# S3 ì—…ë¡œë” í´ë˜ìŠ¤
class S3StreamingUploader:
    def __init__(self, bucket_name, prefix, region_name=None):
        self.s3 = boto3.client('s3', region_name=region_name)
        self.bucket = bucket_name
        self.prefix = prefix

    def upload_pickle_gzip(self, obj, s3_key):
        buf = io.BytesIO()
        with gzip.GzipFile(fileobj=buf, mode='wb') as f:
            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)
        buf.seek(0)
        self.s3.put_object(Bucket=self.bucket, Key=s3_key, Body=buf.read())


def interpolate_individual_landmarks(landmarks_list):
    """ê°œë³„ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ì˜ ê²°ì¸¡ì¹˜ë¥¼ interpolationìœ¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤."""
    if not landmarks_list or len(landmarks_list) < 2:
        return landmarks_list
    
    # ê° ëœë“œë§ˆí¬ íƒ€ì…ë³„ í¬ì¸íŠ¸ ìˆ˜
    landmark_counts = {"pose": 33, "left_hand": 21, "right_hand": 21}
    
    # ê° íƒ€ì…ë³„ë¡œ interpolation ìˆ˜í–‰
    for landmark_type in ["pose", "left_hand", "right_hand"]:
        num_points = landmark_counts[landmark_type]
        
        # ê° í¬ì¸íŠ¸ë³„ë¡œ ì‹œê°„ì¶• interpolation
        for point_idx in range(num_points):
            # í•´ë‹¹ í¬ì¸íŠ¸ì˜ ëª¨ë“  í”„ë ˆì„ì—ì„œì˜ ì¢Œí‘œ ìˆ˜ì§‘
            x_coords, y_coords, z_coords = [], [], []
            valid_frames = []
            
            for frame_idx, frame in enumerate(landmarks_list):
                if frame.get(landmark_type):
                    if isinstance(frame[landmark_type], list):
                        if point_idx < len(frame[landmark_type]):
                            point = frame[landmark_type][point_idx]
                            x_coords.append(point[0])
                            y_coords.append(point[1])
                            z_coords.append(point[2])
                            valid_frames.append(frame_idx)
                    else:
                        # MediaPipe landmark ê°ì²´ì¸ ê²½ìš°
                        landmarks = frame[landmark_type].landmark
                        if point_idx < len(landmarks):
                            x_coords.append(landmarks[point_idx].x)
                            y_coords.append(landmarks[point_idx].y)
                            z_coords.append(landmarks[point_idx].z)
                            valid_frames.append(frame_idx)
            
            # ìœ íš¨í•œ í”„ë ˆì„ì´ 2ê°œ ì´ìƒì¼ ë•Œë§Œ interpolation ìˆ˜í–‰
            if len(valid_frames) >= 2:
                # ì‹œê°„ì¶• interpolation
                x_interp = interp1d(valid_frames, x_coords, kind='linear', 
                                   bounds_error=False, fill_value='extrapolate')
                y_interp = interp1d(valid_frames, y_coords, kind='linear', 
                                   bounds_error=False, fill_value='extrapolate')
                z_interp = interp1d(valid_frames, z_coords, kind='linear', 
                                   bounds_error=False, fill_value='extrapolate')
                
                # ëª¨ë“  í”„ë ˆì„ì— ëŒ€í•´ ë³´ê°„ëœ ê°’ ì ìš©
                for frame_idx in range(len(landmarks_list)):
                    if frame_idx not in valid_frames:
                        # ê²°ì¸¡ í”„ë ˆì„ì— ë³´ê°„ëœ ê°’ ì ìš©
                        interpolated_x = float(x_interp(frame_idx))
                        interpolated_y = float(y_interp(frame_idx))
                        interpolated_z = float(z_interp(frame_idx))
                        
                        # ê¸°ì¡´ í”„ë ˆì„ì— í•´ë‹¹ íƒ€ì…ì´ ì—†ìœ¼ë©´ ìƒì„±
                        if not landmarks_list[frame_idx].get(landmark_type):
                            landmarks_list[frame_idx][landmark_type] = []
                        
                        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
                        if not isinstance(landmarks_list[frame_idx][landmark_type], list):
                            landmarks_list[frame_idx][landmark_type] = [
                                [l.x, l.y, l.z] for l in landmarks_list[frame_idx][landmark_type].landmark
                            ]
                        
                        # í¬ì¸íŠ¸ ê°œìˆ˜ ë§ì¶”ê¸°
                        while len(landmarks_list[frame_idx][landmark_type]) <= point_idx:
                            landmarks_list[frame_idx][landmark_type].append([0, 0, 0])
                        
                        # ë³´ê°„ëœ ê°’ ì ìš©
                        landmarks_list[frame_idx][landmark_type][point_idx] = [
                            interpolated_x, interpolated_y, interpolated_z
                        ]
    
    return landmarks_list


def apply_temporal_smoothing(landmarks_list, window_size=3, alpha=0.7):
    """ì‹œê°„ì  smoothingì„ ì ìš©í•˜ì—¬ ëœë“œë§ˆí¬ ë³€í™”ë¥¼ ë¶€ë“œëŸ½ê²Œ ë§Œë“­ë‹ˆë‹¤."""
    if not landmarks_list or len(landmarks_list) < 2:
        return landmarks_list
    
    smoothed_landmarks = []
    landmark_counts = {"pose": 33, "left_hand": 21, "right_hand": 21}
    
    for frame_idx, frame in enumerate(landmarks_list):
        smoothed_frame = {}
        
        for landmark_type in ["pose", "left_hand", "right_hand"]:
            if not frame.get(landmark_type):
                smoothed_frame[landmark_type] = None
                continue
            
            num_points = landmark_counts[landmark_type]
            smoothed_landmarks_type = []
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
            if not isinstance(frame[landmark_type], list):
                current_landmarks = [[l.x, l.y, l.z] for l in frame[landmark_type].landmark]
            else:
                current_landmarks = frame[landmark_type].copy()
            
            # ê° í¬ì¸íŠ¸ë³„ë¡œ smoothing ì ìš©
            for point_idx in range(num_points):
                if point_idx >= len(current_landmarks):
                    current_landmarks.append([0, 0, 0])
                
                # ìœˆë„ìš° ë‚´ì˜ ì´ì „ í”„ë ˆì„ë“¤ ìˆ˜ì§‘
                window_coords = []
                for w in range(max(0, frame_idx - window_size + 1), frame_idx + 1):
                    if w < len(landmarks_list) and landmarks_list[w].get(landmark_type):
                        if isinstance(landmarks_list[w][landmark_type], list):
                            if point_idx < len(landmarks_list[w][landmark_type]):
                                window_coords.append(landmarks_list[w][landmark_type][point_idx])
                        else:
                            landmarks = landmarks_list[w][landmark_type].landmark
                            if point_idx < len(landmarks):
                                window_coords.append([landmarks[point_idx].x, 
                                                    landmarks[point_idx].y, 
                                                    landmarks[point_idx].z])
                
                if window_coords:
                    # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ìµœê·¼ í”„ë ˆì„ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
                    weights = np.exp(alpha * np.arange(len(window_coords)))
                    weights = weights / np.sum(weights)
                    
                    smoothed_point = [0, 0, 0]
                    for i, coord in enumerate(window_coords):
                        for j in range(3):
                            smoothed_point[j] += coord[j] * weights[i]
                    
                    smoothed_landmarks_type.append(smoothed_point)
                else:
                    smoothed_landmarks_type.append(current_landmarks[point_idx])
            
            smoothed_frame[landmark_type] = smoothed_landmarks_type
        
        smoothed_landmarks.append(smoothed_frame)
    
    return smoothed_landmarks


def check_spatial_consistency_and_correct(landmarks_list):
    """ê³µê°„ì  ì¼ê´€ì„±ì„ ê²€ì‚¬í•˜ê³  ë³´ì •í•©ë‹ˆë‹¤."""
    if not landmarks_list:
        return landmarks_list
    
    corrected_landmarks = []
    landmark_counts = {"pose": 33, "left_hand": 21, "right_hand": 21}
    
    # ì†ëª©-ì†ê°€ë½ ì—°ê²°ì„± ê²€ì‚¬ ë° ë³´ì •
    hand_connections = {
        "left_hand": [(0, 1), (1, 2), (2, 3), (3, 4),  # ì—„ì§€
                     (0, 5), (5, 6), (6, 7), (7, 8),  # ê²€ì§€
                     (0, 9), (9, 10), (10, 11), (11, 12),  # ì¤‘ì§€
                     (0, 13), (13, 14), (14, 15), (15, 16),  # ì•½ì§€
                     (0, 17), (17, 18), (18, 19), (19, 20)],  # ìƒˆë¼
        "right_hand": [(0, 1), (1, 2), (2, 3), (3, 4),  # ì—„ì§€
                      (0, 5), (5, 6), (6, 7), (7, 8),  # ê²€ì§€
                      (0, 9), (9, 10), (10, 11), (11, 12),  # ì¤‘ì§€
                      (0, 13), (13, 14), (14, 15), (15, 16),  # ì•½ì§€
                      (0, 17), (17, 18), (18, 19), (19, 20)]  # ìƒˆë¼
    }
    
    for frame_idx, frame in enumerate(landmarks_list):
        corrected_frame = {}
        
        for landmark_type in ["pose", "left_hand", "right_hand"]:
            if not frame.get(landmark_type):
                corrected_frame[landmark_type] = None
                continue
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
            if not isinstance(frame[landmark_type], list):
                current_landmarks = [[l.x, l.y, l.z] for l in frame[landmark_type].landmark]
            else:
                current_landmarks = frame[landmark_type].copy()
            
            # ì†ì˜ ê²½ìš° ì—°ê²°ì„± ê²€ì‚¬ ë° ë³´ì •
            if landmark_type in ["left_hand", "right_hand"]:
                corrected_landmarks_type = current_landmarks.copy()
                
                # ê° ì—°ê²°ì— ëŒ€í•´ ê±°ë¦¬ ê²€ì‚¬
                for start_idx, end_idx in hand_connections[landmark_type]:
                    if (start_idx < len(corrected_landmarks_type) and 
                        end_idx < len(corrected_landmarks_type)):
                        
                        start_point = corrected_landmarks_type[start_idx]
                        end_point = corrected_landmarks_type[end_idx]
                        
                        # ê±°ë¦¬ ê³„ì‚°
                        distance = np.sqrt(sum((np.array(start_point) - np.array(end_point))**2))
                        
                        # ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ê±°ë¦¬ì¸ ê²½ìš° ë³´ì •
                        max_reasonable_distance = 0.3  # ì„ê³„ê°’
                        if distance > max_reasonable_distance:
                            # ì¤‘ê°„ì ìœ¼ë¡œ ë³´ì •
                            mid_point = [(start_point[i] + end_point[i]) / 2 for i in range(3)]
                            
                            # ì‹œì‘ì ê³¼ ëì ì„ ì¤‘ê°„ì ìœ¼ë¡œë¶€í„° ì ì ˆí•œ ê±°ë¦¬ë¡œ ì¡°ì •
                            direction = np.array(end_point) - np.array(start_point)
                            if np.linalg.norm(direction) > 0:
                                direction = direction / np.linalg.norm(direction)
                                corrected_distance = max_reasonable_distance / 2
                                
                                corrected_landmarks_type[start_idx] = [
                                    mid_point[i] - direction[i] * corrected_distance for i in range(3)
                                ]
                                corrected_landmarks_type[end_idx] = [
                                    mid_point[i] + direction[i] * corrected_distance for i in range(3)
                                ]
                
                corrected_frame[landmark_type] = corrected_landmarks_type
            else:
                # í¬ì¦ˆì˜ ê²½ìš° ê¸°ë³¸ ê²€ì‚¬
                corrected_frame[landmark_type] = current_landmarks
        
        corrected_landmarks.append(corrected_frame)
    
    return corrected_landmarks


def convert_to_relative_coordinates(landmarks_list):
    """ì ˆëŒ€ ì¢Œí‘œë¥¼ ì–´ê¹¨ ì¤‘ì‹¬ ìƒëŒ€ ì¢Œí‘œê³„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    relative_landmarks = []

    for frame in landmarks_list:
        if not frame["pose"]:
            relative_landmarks.append(frame)
            continue

        # ëœë“œë§ˆí¬ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ MediaPipe ê°ì²´ì¸ì§€ í™•ì¸
        if isinstance(frame["pose"], list):
            pose_landmarks = frame["pose"]
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ëœë“œë§ˆí¬ì—ì„œ ì–´ê¹¨ ì¢Œí‘œ ì¶”ì¶œ
            if len(pose_landmarks) > 12:
                left_shoulder = pose_landmarks[11]
                right_shoulder = pose_landmarks[12]
                shoulder_center_x = (left_shoulder[0] + right_shoulder[0]) / 2
                shoulder_center_y = (left_shoulder[1] + right_shoulder[1]) / 2
                shoulder_center_z = (left_shoulder[2] + right_shoulder[2]) / 2
                shoulder_width = abs(right_shoulder[0] - left_shoulder[0])
            else:
                # ì–´ê¹¨ ëœë“œë§ˆí¬ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                shoulder_center_x, shoulder_center_y, shoulder_center_z = 0, 0, 0
                shoulder_width = 1.0
        else:
            # MediaPipe ê°ì²´ì¸ ê²½ìš°
            pose_landmarks = frame["pose"].landmark
            left_shoulder = pose_landmarks[11]
            right_shoulder = pose_landmarks[12]
            shoulder_center_x = (left_shoulder.x + right_shoulder.x) / 2
            shoulder_center_y = (left_shoulder.y + right_shoulder.y) / 2
            shoulder_center_z = (left_shoulder.z + right_shoulder.z) / 2
            shoulder_width = abs(right_shoulder.x - left_shoulder.x)

        if shoulder_width == 0:
            shoulder_width = 1.0

        new_frame = {}

        if frame["pose"]:
            relative_pose = []
            if isinstance(frame["pose"], list):
                for landmark in frame["pose"]:
                    rel_x = (landmark[0] - shoulder_center_x) / shoulder_width
                    rel_y = (landmark[1] - shoulder_center_y) / shoulder_width
                    rel_z = (landmark[2] - shoulder_center_z) / shoulder_width
                    relative_pose.append([rel_x, rel_y, rel_z])
            else:
                for landmark in frame["pose"].landmark:
                    rel_x = (landmark.x - shoulder_center_x) / shoulder_width
                    rel_y = (landmark.y - shoulder_center_y) / shoulder_width
                    rel_z = (landmark.z - shoulder_center_z) / shoulder_width
                    relative_pose.append([rel_x, rel_y, rel_z])
            new_frame["pose"] = relative_pose

        for hand_key in ["left_hand", "right_hand"]:
            if frame[hand_key]:
                relative_hand = []
                if isinstance(frame[hand_key], list):
                    for landmark in frame[hand_key]:
                        rel_x = (landmark[0] - shoulder_center_x) / shoulder_width
                        rel_y = (landmark[1] - shoulder_center_y) / shoulder_width
                        rel_z = (landmark[2] - shoulder_center_z) / shoulder_width
                        relative_hand.append([rel_x, rel_y, rel_z])
                else:
                    for landmark in frame[hand_key].landmark:
                        rel_x = (landmark.x - shoulder_center_x) / shoulder_width
                        rel_y = (landmark.y - shoulder_center_y) / shoulder_width
                        rel_z = (landmark.z - shoulder_center_z) / shoulder_width
                        relative_hand.append([rel_x, rel_y, rel_z])
                new_frame[hand_key] = relative_hand
            else:
                new_frame[hand_key] = None

        relative_landmarks.append(new_frame)

    return relative_landmarks

def enhanced_preprocess_landmarks(landmarks_list):
    """ê°œì„ ëœ ëœë“œë§ˆí¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ - interpolation, smoothing, ì¼ê´€ì„± ê²€ì‚¬ í¬í•¨."""
    if not landmarks_list:
        return np.zeros((TARGET_SEQ_LENGTH, 675))

    print("    ğŸ”§ ê°œë³„ ëœë“œë§ˆí¬ interpolation ì ìš© ì¤‘...")
    # 1. ê°œë³„ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ interpolation
    interpolated_landmarks = interpolate_individual_landmarks(landmarks_list)
    
    print("    ğŸ”§ ì‹œê°„ì  smoothing ì ìš© ì¤‘...")
    # 2. ì‹œê°„ì  smoothing ì ìš©
    smoothed_landmarks = apply_temporal_smoothing(interpolated_landmarks)
    
    print("    ğŸ”§ ê³µê°„ì  ì¼ê´€ì„± ê²€ì‚¬ ë° ë³´ì • ì¤‘...")
    # 3. ê³µê°„ì  ì¼ê´€ì„± ê²€ì‚¬ ë° ë³´ì •
    corrected_landmarks = check_spatial_consistency_and_correct(smoothed_landmarks)
    
    # ê¸°ì¡´ ì „ì²˜ë¦¬ ë¡œì§ ì ìš©
    relative_landmarks = convert_to_relative_coordinates(corrected_landmarks)

    processed_frames = []
    for frame in relative_landmarks:
        combined = []
        for key in ["pose", "left_hand", "right_hand"]:
            if frame[key]:
                # convert_to_relative_coordinatesì—ì„œ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜ë¨
                if isinstance(frame[key], list):
                    combined.extend(frame[key])
                else:
                    # í˜¹ì‹œ MediaPipe ê°ì²´ê°€ ë‚¨ì•„ìˆë‹¤ë©´ ë³€í™˜
                    combined.extend([[l.x, l.y, l.z] for l in frame[key].landmark])
            else:
                num_points = {"pose": 33, "left_hand": 21, "right_hand": 21}[key]
                combined.extend([[0, 0, 0]] * num_points)

        if combined:
            processed_frames.append(np.array(combined).flatten())
        else:
            processed_frames.append(np.zeros(75 * 3))

    if not processed_frames:
        return np.zeros((TARGET_SEQ_LENGTH, 675))

    sequence = np.array(processed_frames)

    if len(sequence) > 0:
        try:
            sequence = normalize_sequence_length(sequence, TARGET_SEQ_LENGTH)
            
            # ê¸°ë³¸ sequence êµ¬ì¡° ê²€ì¦ (ì†ë„, ê°€ì†ë„ ì¶”ê°€ ì „)
            print("    ğŸ” ê¸°ë³¸ sequence êµ¬ì¡° ê²€ì¦ ì¤‘...")
            validate_sequence_structure(sequence)
            
            sequence = extract_dynamic_features(sequence)

            # ì •ê·œí™” ê°œì„ : ë” ê°•í•œ ì •ê·œí™”
            sequence = (sequence - np.mean(sequence)) / (np.std(sequence) + 1e-8)

            return sequence
        except Exception as e:
            print(f"âš ï¸ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return np.zeros((TARGET_SEQ_LENGTH, 675))

    return np.zeros((TARGET_SEQ_LENGTH, 675))


def normalize_sequence_length(sequence, target_length=30):
    """ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    current_length = len(sequence)

    if current_length == target_length:
        return sequence

    x_old = np.linspace(0, 1, current_length)
    x_new = np.linspace(0, 1, target_length)

    normalized_sequence = []
    for i in range(sequence.shape[1]):
        f = interp1d(
            x_old,
            sequence[:, i],
            kind="linear",
            bounds_error=False,
            fill_value="extrapolate",
        )
        normalized_sequence.append(f(x_new))

    return np.array(normalized_sequence).T



def extract_dynamic_features(sequence):
    """ì†ë„ì™€ ê°€ì†ë„ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    velocity = np.diff(sequence, axis=0, prepend=sequence[0:1])
    acceleration = np.diff(velocity, axis=0, prepend=velocity[0:1])
    dynamic_features = np.concatenate([sequence, velocity, acceleration], axis=1)
    return dynamic_features


def validate_sequence_structure(sequence, frame_idx=0):
    """sequenceì˜ êµ¬ì¡°ê°€ pose, left_hand, right_handë¡œ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤."""
    if sequence is None or len(sequence) == 0:
        print("âŒ sequenceê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return False
    
    # ê¸°ë³¸ sequence (ì†ë„, ê°€ì†ë„ ì œì™¸)
    base_sequence_length = sequence.shape[1] // 3  # velocity, acceleration ì œì™¸
    frame_data = sequence[frame_idx][:base_sequence_length]
    
    # ì˜ˆìƒë˜ëŠ” ëœë“œë§ˆí¬ ê°œìˆ˜
    expected_counts = {
        "pose": 33,
        "left_hand": 21, 
        "right_hand": 21
    }
    
    total_expected = sum(expected_counts.values()) * 3  # x, y, z ì¢Œí‘œ
    
    print(f"ğŸ” Sequence êµ¬ì¡° ê²€ì¦:")
    print(f"   ğŸ“Š ì „ì²´ sequence í˜•íƒœ: {sequence.shape}")
    print(f"   ğŸ“Š ê¸°ë³¸ sequence ê¸¸ì´: {base_sequence_length}")
    print(f"   ğŸ“Š ì˜ˆìƒ ëœë“œë§ˆí¬ ê°œìˆ˜: {total_expected}")
    print(f"   ğŸ“Š ì‹¤ì œ ë°ì´í„° ê¸¸ì´: {len(frame_data)}")
    
    if len(frame_data) != total_expected:
        print(f"âŒ ëœë“œë§ˆí¬ ê°œìˆ˜ ë¶ˆì¼ì¹˜: ì˜ˆìƒ {total_expected}, ì‹¤ì œ {len(frame_data)}")
        return False
    
    # ê° ëœë“œë§ˆí¬ íƒ€ì…ë³„ë¡œ ë°ì´í„° í™•ì¸
    start_idx = 0
    for landmark_type, count in expected_counts.items():
        end_idx = start_idx + count * 3
        landmark_data = frame_data[start_idx:end_idx]
        
        print(f"   ğŸ“ {landmark_type}: {count}ê°œ ëœë“œë§ˆí¬, {len(landmark_data)}ê°œ ì¢Œí‘œê°’")
        print(f"      ë²”ìœ„: {start_idx} ~ {end_idx-1}")
        print(f"      ìƒ˜í”Œ ë°ì´í„°: {landmark_data[:6]}...")  # ì²˜ìŒ 6ê°œ ê°’ (2ê°œ ëœë“œë§ˆí¬)
        
        start_idx = end_idx
    
    print("âœ… Sequence êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True



def generate_balanced_none_class_data(file_mapping, none_class, target_count=None):
    """ë‹¤ë¥¸ í´ë˜ìŠ¤ì™€ ê· í˜•ìˆëŠ” None í´ë˜ìŠ¤ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nâœ¨ '{none_class}' í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì¤‘...")

    # ëª©í‘œ ê°œìˆ˜ ê³„ì‚° (ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ í‰ê·  ê°œìˆ˜)
    if target_count is None:
        # ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì˜ ì›ë³¸ íŒŒì¼ ê°œìˆ˜ ê³„ì‚°
        other_class_counts = []
        for filename, info in file_mapping.items():
            if info["label"] != none_class:
                other_class_counts.append(info["label"])

        # ë¼ë²¨ë³„ ê°œìˆ˜ ì§‘ê³„
        from collections import Counter

        label_counts = Counter(other_class_counts)

        if label_counts:
            # ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì˜ í‰ê·  ê°œìˆ˜ ê³„ì‚° (ì¦ê°• í›„ ì˜ˆìƒ ê°œìˆ˜)
            avg_original_count = sum(label_counts.values()) / len(label_counts)
            target_count = int(avg_original_count * (1 + AUGMENTATIONS_PER_VIDEO))
            print(
                f"ğŸ“Š ë‹¤ë¥¸ í´ë˜ìŠ¤ í‰ê· : {avg_original_count:.1f}ê°œ â†’ ëª©í‘œ None í´ë˜ìŠ¤: {target_count}ê°œ"
            )
        else:
            target_count = 100  # ê¸°ë³¸ê°’
            print(f"ğŸ“Š ê¸°ë³¸ ëª©í‘œ None í´ë˜ìŠ¤: {target_count}ê°œ")

    none_samples = []
    source_videos = list(file_mapping.keys())

    # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ë°˜ë³µ
    video_index = 0
    while len(none_samples) < target_count and video_index < len(source_videos):
        filename = source_videos[video_index % len(source_videos)]  # ìˆœí™˜ ì‚¬ìš©
        file_path = file_mapping[filename]["path"]

        try:
            # MediaPipe ê°ì²´ ì¬ì‚¬ìš© (í•œ ë²ˆì— í•˜ë‚˜ì”© ì²˜ë¦¬)
            with MediaPipeManager() as holistic:
                landmarks = extract_landmarks_with_holistic(file_path, holistic)

                if landmarks and len(landmarks) > 10:
                    # ì˜ìƒì˜ ì‹œì‘, 1/4, 1/2, 3/4, ë ì§€ì ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
                    frame_indices = [
                        0,
                        len(landmarks) // 4,
                        len(landmarks) // 2,
                        3 * len(landmarks) // 4,
                        -1,
                    ]

                    for idx in frame_indices:
                        if len(none_samples) >= target_count:
                            break

                        static_landmarks = [landmarks[idx]] * TARGET_SEQ_LENGTH
                        static_sequence = enhanced_preprocess_landmarks(
                            static_landmarks
                        )

                        if static_sequence.shape != (TARGET_SEQ_LENGTH, 675):
                            continue

                        # ì •ì  ì‹œí€€ìŠ¤ ì¶”ê°€
                        none_samples.append(static_sequence)

                        # ë¯¸ì„¸í•œ ì›€ì§ì„ ì¶”ê°€ (ë…¸ì´ì¦ˆ) - ëª©í‘œ ê°œìˆ˜ ì œí•œ
                        for _ in range(
                            min(
                                NONE_CLASS_AUGMENTATIONS_PER_FRAME,
                                target_count - len(none_samples),
                            )
                        ):
                            if len(none_samples) >= target_count:
                                break
                            augmented = augment_sequence_improved(
                                static_sequence, noise_level=NONE_CLASS_NOISE_LEVEL
                            )
                            if augmented.shape == (TARGET_SEQ_LENGTH, 675):
                                none_samples.append(augmented)

                    # ëŠë¦° ì „í™˜ ë°ì´í„° ìƒì„± (ëª©í‘œ ê°œìˆ˜ ì œí•œ)
                    if len(none_samples) < target_count:
                        start_frame_lm = landmarks[0]
                        middle_frame_lm = landmarks[len(landmarks) // 2]

                        transition_landmarks = []
                        for i in range(TARGET_SEQ_LENGTH):
                            alpha = i / (TARGET_SEQ_LENGTH - 1)
                            interp_frame = {}
                            for key in ["pose", "left_hand", "right_hand"]:
                                if start_frame_lm.get(key) and middle_frame_lm.get(key):
                                    interp_lm = []
                                    
                                    # ëœë“œë§ˆí¬ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ MediaPipe ê°ì²´ì¸ì§€ í™•ì¸
                                    if isinstance(start_frame_lm[key], list):
                                        start_lms = start_frame_lm[key]
                                        mid_lms = middle_frame_lm[key]
                                        for j in range(len(start_lms)):
                                            new_x = (
                                                start_lms[j][0] * (1 - alpha)
                                                + mid_lms[j][0] * alpha
                                            )
                                            new_y = (
                                                start_lms[j][1] * (1 - alpha)
                                                + mid_lms[j][1] * alpha
                                            )
                                            new_z = (
                                                start_lms[j][2] * (1 - alpha)
                                                + mid_lms[j][2] * alpha
                                            )
                                            interp_lm.append([new_x, new_y, new_z])
                                    else:
                                        # MediaPipe ê°ì²´ì¸ ê²½ìš°
                                        start_lms = start_frame_lm[key].landmark
                                        mid_lms = middle_frame_lm[key].landmark
                                        for j in range(len(start_lms)):
                                            new_x = (
                                                start_lms[j].x * (1 - alpha)
                                                + mid_lms[j].x * alpha
                                            )
                                            new_y = (
                                                start_lms[j].y * (1 - alpha)
                                                + mid_lms[j].y * alpha
                                            )
                                            new_z = (
                                                start_lms[j].z * (1 - alpha)
                                                + mid_lms[j].z * alpha
                                            )
                                            interp_lm.append([new_x, new_y, new_z])
                                    
                                    interp_frame[key] = interp_lm
                                else:
                                    interp_frame[key] = None
                            transition_landmarks.append(interp_frame)

                        transition_sequence = enhanced_preprocess_landmarks(
                            transition_landmarks
                        )
                        if transition_sequence.shape == (TARGET_SEQ_LENGTH, 675):
                            none_samples.append(transition_sequence)

        except Exception as e:
            print(f"âš ï¸ None í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {filename}, ì˜¤ë¥˜: {e}")

        video_index += 1

    print(
        f"âœ… {none_class} í´ë˜ìŠ¤ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(none_samples)}ê°œ ìƒ˜í”Œ (ëª©í‘œ: {target_count}ê°œ)"
    )

    return none_samples

def validate_video_roots():
    """VIDEO_ROOTSì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    print("ğŸ” ë¹„ë””ì˜¤ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²€ì¦ ì¤‘...")
    valid_roots = []

    for (range_start, range_end), root_path in VIDEO_ROOTS:
        if os.path.exists(root_path):
            valid_roots.append(((range_start, range_end), root_path))
            print(f"âœ… {range_start}~{range_end}: {root_path}")
        else:
            print(f"âŒ {range_start}~{range_end}: {root_path} (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)")

    return valid_roots


def get_video_root_and_path(filename):
    """íŒŒì¼ëª…ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•´ ì˜¬ë°”ë¥¸ VIDEO_ROOT ê²½ë¡œì™€ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # íŒŒì¼ í™•ì¥ì ì œê±°
        file_id = filename.split(".")[0]

        # KETI_SL_ í˜•ì‹ í™•ì¸
        if not file_id.startswith("KETI_SL_"):
            print(f"âš ï¸ KETI_SL_ í˜•ì‹ì´ ì•„ë‹Œ íŒŒì¼ëª…: {filename}")
            return None

        # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
        number_str = file_id.replace("KETI_SL_", "")
        if not number_str.isdigit():
            print(f"âš ï¸ ìˆ«ìê°€ ì•„ë‹Œ íŒŒì¼ëª…: {filename}")
            return None

        num = int(number_str)

        # ì ì ˆí•œ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        target_root = None
        for (range_start, range_end), root_path in VIDEO_ROOTS:
            if range_start <= num <= range_end:
                target_root = root_path
                break

        if target_root is None:
            print(f"âš ï¸ ë²ˆí˜¸ {num}ì— í•´ë‹¹í•˜ëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
            return None

        # íŒŒì¼ ì°¾ê¸°
        file_path = find_file_in_directory(target_root, filename)
        if file_path:
            return file_path

        print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename} (ë””ë ‰í† ë¦¬: {target_root})")
        return None

    except Exception as e:
        print(f"âš ï¸ íŒŒì¼ëª… íŒŒì‹± ì˜¤ë¥˜: {filename}, ì˜¤ë¥˜: {e}")
        return None
    
    
def find_file_in_directory(directory, filename_pattern):
    """ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    if not os.path.exists(directory):
        return None

    # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
    base_name = filename_pattern.split(".")[0]

    # ê°€ëŠ¥í•œ í™•ì¥ìë“¤ (configì—ì„œ ê°€ì ¸ì˜´)
    for ext in VIDEO_EXTENSIONS:
        candidate = os.path.join(directory, base_name + ext)
        if os.path.exists(candidate):
            return candidate

    return None



def extract_landmarks_with_holistic(video_path, holistic):
    """ì „ë‹¬ë°›ì€ MediaPipe ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŒ: {video_path}")
            return None

        # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        print(f"    ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {total_frames}í”„ë ˆì„, {fps:.1f}fps")

        landmarks_list = []
        frame_count = 0

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            # í”„ë ˆì„ ì²˜ë¦¬
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = holistic.process(rgb_frame)

            frame_data = {
                "pose": results.pose_landmarks,
                "left_hand": results.left_hand_landmarks,
                "right_hand": results.right_hand_landmarks,
            }
            landmarks_list.append(frame_data)
            frame_count += 1
            
        cap.release()
        print(f"    âœ… ëœë“œë§ˆí¬ ì¶”ì¶œ ì™„ë£Œ: {len(landmarks_list)}í”„ë ˆì„")
        return landmarks_list

    except (cv2.error, OSError) as e:
        print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {video_path}, ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"âš ï¸ ëœë“œë§ˆí¬ ì¶”ì¶œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {video_path}, ì˜¤ë¥˜: {e}")
        return None

def extract_and_cache_label_data_optimized(file_mapping, label):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë¼ë²¨ë³„ ë°ì´í„° ì¶”ì¶œ ë° ìºì‹±"""
    print(f"\nğŸ”„ {label} ë¼ë²¨ ë°ì´í„° ì¶”ì¶œ ì¤‘...")

    # í•´ë‹¹ ë¼ë²¨ì˜ íŒŒì¼ë“¤ë§Œ í•„í„°ë§
    label_files = {
        filename: info
        for filename, info in file_mapping.items()
        if info["label"] == label
    }

    if not label_files:
        print(f"âš ï¸ {label} ë¼ë²¨ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    label_data = []

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for batch in process_data_in_batches(
        label_files, batch_size=BATCH_SIZE_FOR_PROCESSING
    ):
        for item in batch:
            if item["label"] == label:
                # ì›ë³¸ ë°ì´í„° ì¶”ê°€
                label_data.append(item["sequence"])

                # ì¦ê°• ë°ì´í„° ì¶”ê°€
                for _ in range(AUGMENTATIONS_PER_VIDEO):
                    try:
                        augmented = augment_sequence_improved(item["sequence"])
                        if augmented.shape == (TARGET_SEQ_LENGTH, 675):
                            label_data.append(augmented)
                    except Exception as e:
                        print(f"âš ï¸ ì¦ê°• ì¤‘ ì˜¤ë¥˜: {e}")
                        continue

    print(f"âœ… {label} ë¼ë²¨ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(label_data)}ê°œ ìƒ˜í”Œ")

    # ìºì‹œì— ì €ì¥
    save_label_cache(label, label_data)

    return label_data

def process_data_in_batches(file_mapping, batch_size=100):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    all_files = list(file_mapping.items())
    total_files = len(all_files)

    print(f"ğŸ“Š ì´ {total_files}ê°œ íŒŒì¼ì„ {batch_size}ê°œì”© ë°°ì¹˜ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # ì§„í–‰ë¥  í‘œì‹œ ì„¤ì •ì— ë”°ë¼ tqdm ì‚¬ìš©
    if ENABLE_PROGRESS_BAR:
        iterator = tqdm(range(0, total_files, batch_size), desc="ë°°ì¹˜ ì²˜ë¦¬")
    else:
        iterator = range(0, total_files, batch_size)

    # MediaPipe ê°ì²´ ì¬ì‚¬ìš©
    try:
        with MediaPipeManager() as holistic:
            print("âœ… MediaPipe ê°ì²´ ì´ˆê¸°í™” ì™„ë£Œ")

            for i in iterator:
                batch_files = all_files[i : i + batch_size]
                batch_data = []

                print(
                    f"ğŸ”„ ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì¤‘... ({len(batch_files)}ê°œ íŒŒì¼)"
                )

                for filename, info in batch_files:
                    try:
                        print(f"  ğŸ“¹ {filename} ì²˜ë¦¬ ì¤‘...")
                        landmarks = extract_landmarks_with_holistic(
                            info["path"], holistic
                        )
                        if not landmarks:
                            print(f"    âš ï¸ ëœë“œë§ˆí¬ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
                            continue

                        processed_sequence = enhanced_preprocess_landmarks(landmarks)
                        if processed_sequence.shape != (TARGET_SEQ_LENGTH, 675):
                            print(
                                f"    âš ï¸ ì‹œí€€ìŠ¤ í˜•íƒœ ë¶ˆì¼ì¹˜: {filename} - {processed_sequence.shape}"
                            )
                            continue

                        batch_data.append(
                            {
                                "sequence": processed_sequence,
                                "label": info["label"],
                                "filename": filename,
                            }
                        )
                        print(f"    âœ… ì„±ê³µ: {filename}")

                    except Exception as e:
                        print(f"    âŒ ì˜¤ë¥˜: {filename} - {e}")
                        continue

                print(f"âœ… ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ: {len(batch_data)}ê°œ ì„±ê³µ")
                yield batch_data

    except Exception as e:
        print(f"âŒ MediaPipe ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        yield []


def augment_sequence_improved(
    sequence,
    noise_level=AUGMENTATION_NOISE_LEVEL,
    scale_range=AUGMENTATION_SCALE_RANGE,
    rotation_range=AUGMENTATION_ROTATION_RANGE,
):
    """ê°œì„ ëœ ì‹œí€€ìŠ¤ ì¦ê°•."""
    augmented = sequence.copy()

    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = np.random.normal(0, noise_level, augmented.shape)
    augmented += noise

    # ìŠ¤ì¼€ì¼ë§
    scale_factor = np.random.uniform(1 - scale_range, 1 + scale_range)
    augmented *= scale_factor

    # ì‹œê°„ì¶•ì—ì„œì˜ íšŒì „ (ì‹œí”„íŠ¸)
    shift = np.random.randint(-3, 4)
    if shift > 0:
        augmented = np.roll(augmented, shift, axis=0)
    elif shift < 0:
        augmented = np.roll(augmented, shift, axis=0)

    return augmented


def save_label_cache(label, data):
    """ë¼ë²¨ë³„ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    cache_path = get_label_cache_path(label)
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    cache_dir = os.path.dirname(cache_path)
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir, exist_ok=True)

    # ìºì‹œì— ì €ì¥í•  ë°ì´í„°ì™€ íŒŒë¼ë¯¸í„° ì •ë³´
    cache_data = {
        "data": data,
        "parameters": {
            "TARGET_SEQ_LENGTH": TARGET_SEQ_LENGTH,
            "AUGMENTATIONS_PER_VIDEO": AUGMENTATIONS_PER_VIDEO,
            "AUGMENTATION_NOISE_LEVEL": AUGMENTATION_NOISE_LEVEL,
            "AUGMENTATION_SCALE_RANGE": AUGMENTATION_SCALE_RANGE,
            "AUGMENTATION_ROTATION_RANGE": AUGMENTATION_ROTATION_RANGE,
            "NONE_CLASS_NOISE_LEVEL": NONE_CLASS_NOISE_LEVEL,
            "NONE_CLASS_AUGMENTATIONS_PER_FRAME": NONE_CLASS_AUGMENTATIONS_PER_FRAME,
            # ë°ì´í„° ê°œìˆ˜ ê´€ë ¨ íŒŒë¼ë¯¸í„° ì¶”ê°€
            "LABEL_MAX_SAMPLES_PER_CLASS": LABEL_MAX_SAMPLES_PER_CLASS,
            "MIN_SAMPLES_PER_CLASS": MIN_SAMPLES_PER_CLASS,
        },
    }

    # ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì €ì¥ (ì›ìì  ì“°ê¸°)
    temp_path = cache_path + ".tmp"

    try:
        with open(temp_path, "wb") as f:
            pickle.dump(cache_data, f, protocol=pickle.HIGHEST_PROTOCOL)

        # ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ë©´ ìµœì¢… ìœ„ì¹˜ë¡œ ì´ë™
        os.replace(temp_path, cache_path)
        print(f"ğŸ’¾ {label} ë¼ë²¨ ë°ì´í„° ìºì‹œ ì €ì¥: {cache_path} ({len(data)}ê°œ ìƒ˜í”Œ)")

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise e

# ë¼ë²¨ë³„ ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„± í•¨ìˆ˜
def get_label_cache_path(label):
    """ë¼ë²¨ë³„ ìºì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì£¼ìš” íŒŒë¼ë¯¸í„°ë¥¼ íŒŒì¼ëª…ì— í¬í•¨ì‹œì¼œ ìºì‹œ ë¬´íš¨í™”ê°€ ìë™ìœ¼ë¡œ ë˜ë„ë¡ í•©ë‹ˆë‹¤."""
    safe_label = label.replace(" ", "_").replace("/", "_")

    # ë°ì´í„° ê°œìˆ˜ ê´€ë ¨ íŒŒë¼ë¯¸í„°ë“¤ì„ íŒŒì¼ëª…ì— í¬í•¨
    max_samples_str = (
        f"max{LABEL_MAX_SAMPLES_PER_CLASS}"
        if LABEL_MAX_SAMPLES_PER_CLASS
        else "maxNone"
    )
    min_samples_str = f"min{MIN_SAMPLES_PER_CLASS}"

    return os.path.join(
        CACHE_DIR,
        f"{safe_label}_seq{TARGET_SEQ_LENGTH}_aug{AUGMENTATIONS_PER_VIDEO}_{max_samples_str}_{min_samples_str}.pkl",
    )



# ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë¯¸ë””ì–´íŒŒì´í”„ ì‹œí€€ìŠ¤ ì¶”ì¶œ ë° S3 ì—…ë¡œë“œ í†µí•© íŒŒì´í”„ë¼ì¸")
    parser.add_argument('--config', type=str, default='spec.json', help='ì„¤ì • íŒŒì¼(JSON) ê²½ë¡œ (ê¸°ë³¸ê°’: spec.json)')
    parser.add_argument('--s3-bucket', type=str, default='waterandfish-s3', help='S3 ë²„í‚· ì´ë¦„ (ê¸°ë³¸ê°’: waterandfish-s3)')
    parser.add_argument('--s3-prefix', type=str, default='feature-extraction-cache', help='S3 ì—…ë¡œë“œ ê²½ë¡œ prefix (ê¸°ë³¸ê°’: feature-extraction-cache)')
    parser.add_argument('--region', type=str, default='ap-northeast-2', help='S3 ë¦¬ì „ (ê¸°ë³¸ê°’: ap-northeast-2)')
    parser.add_argument('--upload', action='store_true', default=True, help='S3 ì—…ë¡œë“œ ì‹¤í–‰ (ê¸°ë³¸ê°’: True)')
    args = parser.parse_args()
    uploader = S3StreamingUploader(args.s3_bucket, args.s3_prefix, args.region)

    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # args.configë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ì • íŒŒì¼ ì½ê¸°
    with open(args.config, "r") as f:
        params = json.load(f)
    label_dict = params["label_dict"]

    ACTIONS = list(label_dict.keys())
    NONE_CLASS = ACTIONS[-1]

    print(f"ğŸ”§ ë¼ë²¨ ëª©ë¡: {ACTIONS}")
    # 1. ë¹„ë””ì˜¤ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²€ì¦
    valid_roots = validate_video_roots()
    if not valid_roots:
        print("âŒ ìœ íš¨í•œ ë¹„ë””ì˜¤ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # 2. labels.csv íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    if not os.path.exists("labels.csv"):
        print("âŒ labels.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    labels_df = pd.read_csv("labels.csv")
    print(f"ğŸ“Š labels.csv ë¡œë“œ ì™„ë£Œ: {len(labels_df)}ê°œ í•­ëª©")
    print(labels_df.head())

    # 3. íŒŒì¼ëª…ì—ì„œ ë¹„ë””ì˜¤ ë£¨íŠ¸ ê²½ë¡œ ì¶”ì¶œ (ê°œì„ ëœ ë°©ì‹)
    print("\nğŸ” íŒŒì¼ëª… ë¶„ì„ ë° ê²½ë¡œ ë§¤í•‘ ì¤‘...")
    file_mapping = {}
    found_files = 0
    missing_files = 0
    filtered_files = 0

    # ë¼ë²¨ë³„ë¡œ íŒŒì¼ì„ ëª¨ì•„ì„œ ìµœëŒ€ ê°œìˆ˜ë§Œí¼ë§Œ ìƒ˜í”Œë§
    label_to_files = defaultdict(list)
    for idx, row in labels_df.iterrows():
        filename = row["íŒŒì¼ëª…"]
        label = row["í•œêµ­ì–´"]
        if label not in ACTIONS:
            continue
        file_path = get_video_root_and_path(filename)
        if file_path:
            label_to_files[label].append((filename, file_path))
            found_files += 1
            filtered_files += 1
        else:
            missing_files += 1

    # ìµœëŒ€ ê°œìˆ˜ë§Œí¼ë§Œ ìƒ˜í”Œë§
    for label in ACTIONS:
        files = label_to_files[label]
        if LABEL_MAX_SAMPLES_PER_CLASS is not None:
            files = files[:LABEL_MAX_SAMPLES_PER_CLASS]
        for filename, file_path in files:
            file_mapping[filename] = {"path": file_path, "label": label}

    # [ìˆ˜ì •] ë¼ë²¨ë³„ ì›ë³¸ ì˜ìƒ ê°œìˆ˜ ì²´í¬ ë° ìµœì†Œ ê°œìˆ˜ ë¯¸ë‹¬ ì‹œ í•™ìŠµ ì¤‘ë‹¨ (Noneì€ ì˜ˆì™¸)
    insufficient_labels = []
    for label in ACTIONS:
        if label == NONE_CLASS:
            continue  # None í´ë˜ìŠ¤ëŠ” ì˜ˆì™¸
        num_samples = len(label_to_files[label])
        if num_samples < MIN_SAMPLES_PER_CLASS:
            insufficient_labels.append((label, num_samples))
    if insufficient_labels:
        print("\nâŒ ìµœì†Œ ìƒ˜í”Œ ê°œìˆ˜ ë¯¸ë‹¬ ë¼ë²¨ ë°œê²¬! í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        for label, count in insufficient_labels:
            print(f"   - {label}: {count}ê°œ (ìµœì†Œ í•„ìš”: {MIN_SAMPLES_PER_CLASS}ê°œ)")
        sys.exit(1)

    print(f"\nğŸ“Š íŒŒì¼ ë§¤í•‘ ê²°ê³¼:")
    print(f"   âœ… ì°¾ì€ íŒŒì¼: {found_files}ê°œ")
    print(f"   âŒ ëˆ„ë½ëœ íŒŒì¼: {missing_files}ê°œ")
    print(f"   ğŸ¯ ACTIONS ë¼ë²¨ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼: {filtered_files}ê°œ")
    print(f"   âš¡ ë¼ë²¨ë³„ ìµœëŒ€ {LABEL_MAX_SAMPLES_PER_CLASS}ê°œ íŒŒì¼ë§Œ ì‚¬ìš©")
    print(f"   âš¡ ë¼ë²¨ë³„ ìµœì†Œ {MIN_SAMPLES_PER_CLASS}ê°œ íŒŒì¼ í•„ìš”")

    if len(file_mapping) == 0:
        print("âŒ ì°¾ì„ ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # 4. ë¼ë²¨ë³„ ë°ì´í„° ì¶”ì¶œ ë° ìºì‹± (ê°œë³„ ì²˜ë¦¬)
    print("\nğŸš€ ë¼ë²¨ë³„ ë°ì´í„° ì¶”ì¶œ ë° ìºì‹± ì‹œì‘...")

    # None í´ë˜ìŠ¤ ì œì™¸í•œ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì˜ í‰ê·  ê°œìˆ˜ ê³„ì‚°
    other_class_counts = {}
    for filename, info in file_mapping.items():
        if info["label"] != NONE_CLASS:
            label = info["label"]
            other_class_counts[label] = other_class_counts.get(label, 0) + 1

    if other_class_counts:
        avg_other_class_count = sum(other_class_counts.values()) / len(
            other_class_counts
        )
        target_none_count = int(avg_other_class_count * (1 + AUGMENTATIONS_PER_VIDEO))
        print(
            f"ğŸ“Š ë‹¤ë¥¸ í´ë˜ìŠ¤ í‰ê· : {avg_other_class_count:.1f}ê°œ â†’ None í´ë˜ìŠ¤ ëª©í‘œ: {target_none_count}ê°œ"
        )
    else:
        target_none_count = None
        print(f"ğŸ“Š ë‹¤ë¥¸ í´ë˜ìŠ¤ê°€ ì—†ìŒ â†’ None í´ë˜ìŠ¤ ê¸°ë³¸ê°’ ì‚¬ìš©")

    X = []
    y = []

    for label in ACTIONS:
        print(f"\n{'='*50}")
        print(f"ğŸ“‹ {label} ë¼ë²¨ ì²˜ë¦¬ ì¤‘...")
        print(f"{'='*50}")

        if label == NONE_CLASS:
            label_data = generate_balanced_none_class_data(
                file_mapping, NONE_CLASS, target_none_count
            )
        else:
            label_data = extract_and_cache_label_data_optimized(file_mapping, label)

        if label_data:
            label_index = get_action_index(label, ACTIONS)
            X.extend(label_data)
            y.extend([label_index] * len(label_data))
            print(f"âœ… {label}: {len(label_data)}ê°œ ìƒ˜í”Œ ì¶”ê°€ë¨")
        else:
            print(f"âš ï¸ {label}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"\n{'='*50}")
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í†µê³„:")
    print(f"{'='*50}")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")

    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    unique, counts = np.unique(y, return_counts=True)
    for class_idx, count in zip(unique, counts):
        if 0 <= class_idx < len(ACTIONS):
            print(f"í´ë˜ìŠ¤ {class_idx} ({ACTIONS[class_idx]}): {count}ê°œ")
        else:
            print(f"í´ë˜ìŠ¤ {class_idx} (Unknown): {count}ê°œ")

    # S3 ì—…ë¡œë“œ
    if args.upload:
        s3_key = f"{args.s3_prefix}/{label}.pkl.gz"
        print(f"S3 ì—…ë¡œë“œ: {s3_key}")
        uploader.upload_pickle_gzip(label_data, s3_key)
        print(f"âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: {s3_key}")

    print("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!") 