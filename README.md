# S3 Uploader Package

ë¯¸ë””ì–´íŒŒì´í”„ ì‹œí€€ìŠ¤ ì¶”ì¶œ ë° S3 ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸ íŒ¨í‚¤ì§€

## ğŸ“¦ ì„¤ì¹˜

### PyPIì—ì„œ ì„¤ì¹˜ (ê¶Œì¥)
```bash
pip install s3-uploader
```

### ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜
```bash
git clone https://github.com/your-username/s3-uploader.git
cd s3-uploader
pip install -e .
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. AWS ì„¤ì •
```bash
# AWS CLI ì„¤ì¹˜
pip install awscli

# AWS ìê²© ì¦ëª… ì„¤ì •
aws configure
```

### 2. ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# ì„¤ì • íŒŒì¼ ìƒì„±
s3-uploader-config --preset development --output config.json

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
s3-uploader \
  --video-dir /path/to/videos \
  --s3-bucket your-bucket-name \
  --s3-prefix sequences
```

### 3. Python ì½”ë“œì—ì„œ ì‚¬ìš©
```python
from s3_uploader import MediaPipeS3StreamingPipeline

# íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
pipeline = MediaPipeS3StreamingPipeline(
    video_dir="/path/to/videos",
    s3_bucket="your-bucket-name",
    s3_prefix="sequences",
    aws_region="us-east-1"
)

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
result = pipeline.run_streaming_pipeline(
    target_fps=30,
    max_frames=None
)

print(f"ì²˜ë¦¬ ì™„ë£Œ: {result['processed_videos']}ê°œ ë¹„ë””ì˜¤")
```

## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥

- **ë¯¸ë””ì–´íŒŒì´í”„ ì‹œí€€ìŠ¤ ì¶”ì¶œ**: í¬ì¦ˆ, ì† ëœë“œë§ˆí¬ ì¶”ì¶œ
- **ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë¦¬ë°**: ë¡œì»¬ ì €ì¥ ì—†ì´ ì§ì ‘ S3 ì—…ë¡œë“œ
- **ë³‘ë ¬ ì²˜ë¦¬**: ë©€í‹°ìŠ¤ë ˆë“œ ì—…ë¡œë“œ ì§€ì›
- **ì••ì¶• ìµœì í™”**: pickle + gzip ì••ì¶•ìœ¼ë¡œ í¬ê¸° ì ˆì•½
- **ì„¤ì • ê´€ë¦¬**: JSON ê¸°ë°˜ ì„¤ì • íŒŒì¼ ì§€ì›

## âš™ï¸ ì„¤ì •

### í™˜ê²½ë³„ í”„ë¦¬ì…‹
```bash
# ê°œë°œ í™˜ê²½ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
s3-uploader-config --preset development

# í”„ë¡œë•ì…˜ í™˜ê²½ (ê³ í’ˆì§ˆ)
s3-uploader-config --preset production

# ê³ ì •í™•ë„ í™˜ê²½ (ì—°êµ¬ìš©)
s3-uploader-config --preset high_accuracy

# ë¹ ë¥¸ ì²˜ë¦¬ í™˜ê²½
s3-uploader-config --preset fast_processing
```

### ì»¤ìŠ¤í…€ ì„¤ì •
```json
{
  "video": {
    "target_fps": 30,
    "max_frames": null
  },
  "mediapipe": {
    "model_complexity": 1,
    "min_detection_confidence": 0.5
  },
  "s3": {
    "max_workers": 4,
    "chunk_size": 8388608
  }
}
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
```python
from s3_uploader import MediaPipeStreamingExtractor, S3StreamingUploader

# ì¶”ì¶œê¸°ë§Œ ì‚¬ìš©
extractor = MediaPipeStreamingExtractor(
    model_complexity=1,
    min_detection_confidence=0.5
)

compressed_data, metadata = extractor.extract_sequence_to_memory(
    video_path="video.mp4",
    target_fps=30
)

# ì—…ë¡œë”ë§Œ ì‚¬ìš©
uploader = S3StreamingUploader(
    bucket_name="your-bucket",
    region_name="us-east-1"
)

result = uploader.upload_data_streaming(
    data=compressed_data,
    s3_key="sequences/video_landmarks.pkl.gz"
)
```

### ë°°ì¹˜ ì²˜ë¦¬
```python
import glob
from pathlib import Path

# ì—¬ëŸ¬ ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ ì²˜ë¦¬
video_dirs = glob.glob("/path/to/videos/*")

for video_dir in video_dirs:
    pipeline = MediaPipeS3StreamingPipeline(
        video_dir=video_dir,
        s3_bucket="your-bucket",
        s3_prefix=f"sequences/{Path(video_dir).name}"
    )
    
    result = pipeline.run_streaming_pipeline()
    print(f"{video_dir}: {result['processed_videos']}ê°œ ì²˜ë¦¬")
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ê¶Œì¥ ì„¤ì •

| í™˜ê²½ | target_fps | model_complexity | max_workers | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|------|------------|------------------|-------------|---------------|
| ê°œë°œ | 15 | 0 | 2 | 4GB |
| í”„ë¡œë•ì…˜ | 30 | 1 | 4 | 8GB |
| ê³ ì •í™•ë„ | 60 | 2 | 2 | 16GB |

### ì„±ëŠ¥ íŒ

1. **GPU ì‚¬ìš©**: CUDA ì§€ì› GPUê°€ ìˆìœ¼ë©´ ì²˜ë¦¬ ì†ë„ í–¥ìƒ
2. **ë³‘ë ¬ ì²˜ë¦¬**: `max_workers` ì¦ê°€ë¡œ ì—…ë¡œë“œ ì†ë„ í–¥ìƒ
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: `max_frames` ì„¤ì •ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´
4. **ë„¤íŠ¸ì›Œí¬ ìµœì í™”**: AWS ë¦¬ì „ê³¼ ê°€ê¹Œìš´ ìœ„ì¹˜ì—ì„œ ì‹¤í–‰

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ë¯¸ë””ì–´íŒŒì´í”„ ì„¤ì¹˜ ì˜¤ë¥˜
```bash
pip uninstall opencv-python
pip install opencv-python-headless
pip install mediapipe
```

#### 2. AWS ê¶Œí•œ ì˜¤ë¥˜
```bash
aws sts get-caller-identity
aws s3 ls s3://your-bucket-name
```

#### 3. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ì„¤ì •ì—ì„œ ë©”ëª¨ë¦¬ ì œí•œ ì¡°ì •
{
  "performance": {
    "memory_limit_gb": 4
  }
}
```

## ğŸ“ˆ ì˜ˆì‹œ

### ê¸°ë³¸ ì˜ˆì‹œ
```python
from s3_uploader import MediaPipeS3StreamingPipeline

pipeline = MediaPipeS3StreamingPipeline(
    video_dir="/Volumes/ExternalHD/videos",
    s3_bucket="my-ml-bucket",
    s3_prefix="pose-sequences"
)

result = pipeline.run_streaming_pipeline(
    target_fps=30,
    max_frames=None
)

print(f"ì„±ê³µ: {result['processed_videos']}ê°œ")
print(f"ì‹¤íŒ¨: {result['failed_videos']}ê°œ")
```

### ê³ ê¸‰ ì˜ˆì‹œ
```python
from s3_uploader import MediaPipeS3StreamingPipeline
from s3_uploader import PipelineConfig

# ì»¤ìŠ¤í…€ ì„¤ì •
config = PipelineConfig()
config.set('video.target_fps', 60)
config.set('mediapipe.model_complexity', 2)
config.set('s3.max_workers', 8)

pipeline = MediaPipeS3StreamingPipeline(
    video_dir="/path/to/videos",
    s3_bucket="your-bucket",
    s3_prefix="high-quality-sequences",
    **config.get_extractor_kwargs()
)

result = pipeline.run_streaming_pipeline()
```

## ğŸ“š API ë¬¸ì„œ

### MediaPipeS3StreamingPipeline

ë©”ì¸ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤

```python
class MediaPipeS3StreamingPipeline:
    def __init__(
        self,
        video_dir: str,
        s3_bucket: str,
        s3_prefix: str,
        aws_region: str = "us-east-1",
        **kwargs
    ):
        """
        Args:
            video_dir: ë¹„ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
            s3_bucket: S3 ë²„í‚· ì´ë¦„
            s3_prefix: S3 í‚¤ ì ‘ë‘ì‚¬
            aws_region: AWS ë¦¬ì „
            **kwargs: MediaPipe ì„¤ì • íŒŒë¼ë¯¸í„°
        """
    
    def run_streaming_pipeline(
        self,
        target_fps: int = 30,
        max_frames: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Returns:
            Dict containing processing results
        """
```

### MediaPipeStreamingExtractor

ë¯¸ë””ì–´íŒŒì´í”„ ì¶”ì¶œê¸°

```python
class MediaPipeStreamingExtractor:
    def extract_sequence_to_memory(
        self,
        video_path: str,
        target_fps: int = 30
    ) -> Tuple[bytes, Dict[str, Any]]:
        """
        ë¹„ë””ì˜¤ì—ì„œ ëœë“œë§ˆí¬ ì‹œí€€ìŠ¤ ì¶”ì¶œ
        
        Returns:
            Tuple of (compressed_data, metadata)
        """
```

### S3StreamingUploader

S3 ì—…ë¡œë”

```python
class S3StreamingUploader:
    def upload_data_streaming(
        self,
        data: bytes,
        s3_key: str
    ) -> Dict[str, Any]:
        """
        ë°ì´í„°ë¥¼ S3ì— ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ
        
        Returns:
            Dict containing upload results
        """
```

## ğŸ”— ì˜ì¡´ì„±

- **mediapipe**: í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
- **opencv-python**: ë¹„ë””ì˜¤ ì²˜ë¦¬
- **boto3**: AWS S3 ì—…ë¡œë“œ
- **numpy**: ìˆ˜ì¹˜ ê³„ì‚°
- **pickle**: ë°ì´í„° ì§ë ¬í™”
- **gzip**: ë°ì´í„° ì••ì¶•

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”. 